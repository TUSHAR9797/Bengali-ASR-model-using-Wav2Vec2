{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n    print('Not connected to a GPU')\nelse:\n    print(gpu_info)","metadata":{"id":"YELVqGxMxnbG","outputId":"1ab7eb67-409d-4371-b99e-7eb1171cb5fb","execution":{"iopub.status.busy":"2022-08-21T17:14:53.349071Z","iopub.execute_input":"2022-08-21T17:14:53.350974Z","iopub.status.idle":"2022-08-21T17:14:53.500685Z","shell.execute_reply.started":"2022-08-21T17:14:53.350781Z","shell.execute_reply":"2022-08-21T17:14:53.498996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install datasets\n!pip install transformers\n!pip install torchaudio\n!pip install jiwer","metadata":{"id":"c8eh87Hoee5d","execution":{"iopub.status.busy":"2022-08-21T17:14:53.505384Z","iopub.execute_input":"2022-08-21T17:14:53.505832Z","iopub.status.idle":"2022-08-21T17:15:46.269673Z","shell.execute_reply.started":"2022-08-21T17:14:53.505788Z","shell.execute_reply":"2022-08-21T17:15:46.26773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Data, Tokenizer, Feature Extractor","metadata":{"id":"0mW-C1Nt-j7k"}},{"cell_type":"markdown","source":"Common Voice has many different splits including `invalidated`, which refers to data that was not rated as \"clean enough\" to be considered useful. In this notebook, we will only make use of the splits `\"train\"`, `\"validation\"` and `\"test\"`. ","metadata":{"id":"bee4g9rpLxll"}},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, Audio","metadata":{"id":"2MMXcWFFgCXU","outputId":"00961862-9e79-4e0e-c887-db62adafa553","execution":{"iopub.status.busy":"2022-08-21T17:15:46.273201Z","iopub.execute_input":"2022-08-21T17:15:46.274165Z","iopub.status.idle":"2022-08-21T17:15:56.116946Z","shell.execute_reply.started":"2022-08-21T17:15:46.274091Z","shell.execute_reply":"2022-08-21T17:15:56.11551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"id":"svKzVJ_hQGK6","execution":{"iopub.status.busy":"2022-08-21T17:15:56.167374Z","iopub.execute_input":"2022-08-21T17:15:56.167961Z","iopub.status.idle":"2022-08-21T17:15:56.177135Z","shell.execute_reply.started":"2022-08-21T17:15:56.167918Z","shell.execute_reply":"2022-08-21T17:15:56.175433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df=pd.read_csv('../input/dlsprint/train.csv')\nparent_dir='../input/train-wavs-all-dl-sprint/train_wavs/'\nwav_path=[parent_dir+x.split('.')[0]+'.wav' for x in list(train_df['path'])]\ntrain_df['wav_path']=wav_path","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:56.457667Z","iopub.execute_input":"2022-08-21T17:15:56.458437Z","iopub.status.idle":"2022-08-21T17:15:58.820722Z","shell.execute_reply.started":"2022-08-21T17:15:56.458373Z","shell.execute_reply":"2022-08-21T17:15:58.819336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df=pd.read_csv('../input/dlsprint/validation.csv')\nparent_dir='../input/dl-sprint-validation-16k/validation_files_wav/'\nwav_path=[parent_dir+x.split('.')[0]+'.wav' for x in list(valid_df['path'])]\nvalid_df['wav_path']=wav_path","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:58.822785Z","iopub.execute_input":"2022-08-21T17:15:58.823201Z","iopub.status.idle":"2022-08-21T17:15:58.925668Z","shell.execute_reply.started":"2022-08-21T17:15:58.823142Z","shell.execute_reply":"2022-08-21T17:15:58.924292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:58.949727Z","iopub.execute_input":"2022-08-21T17:15:58.951339Z","iopub.status.idle":"2022-08-21T17:15:58.99395Z","shell.execute_reply.started":"2022-08-21T17:15:58.951295Z","shell.execute_reply":"2022-08-21T17:15:58.992671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.io import wavfile\ndef wav_read(filename):\n    #print(filename)\n    sampling_rate, wave = wavfile.read(filename)\n    \n    speech_array = np.float32(wave) / (2**15 - 1)\n    return speech_array,sampling_rate","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:58.99558Z","iopub.execute_input":"2022-08-21T17:15:58.996914Z","iopub.status.idle":"2022-08-21T17:15:59.05033Z","shell.execute_reply.started":"2022-08-21T17:15:58.996856Z","shell.execute_reply":"2022-08-21T17:15:59.04892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vocabulary disctionary is kept exactly same as the pretrained model","metadata":{}},{"cell_type":"code","source":"vocab_dict={\"<s>\": 1, \"<pad>\": 0, \"</s>\": 2, \"<unk>\": 3, \"ই\": 4, \"3\": 5, \"হ\": 6, \"…\": 7, \"ল\": 8, \"্\": 9, \"ৈ\": 10, \"ো\": 11, \"৪\": 12, \"ধ\": 13, \"উ\": 14, \"া\": 15, \"ঞ\": 16, \"F\": 17, \"অ\": 18, \"ও\": 19, \"ট\": 20, \"খ\": 21, \"ড়\": 22, \"স\": 23, \"০\": 24, \"ম\": 25, \"ং\": 26, \"ৌ\": 27, \"গ\": 28, \"ঃ\": 29, \"‌\": 30, \"থ\": 31, \"e\": 32, \"ি\": 33, \"ষ\": 34, \"৯\": 35, \"়\": 36, \"চ\": 37, \"শ\": 38, \"ৗ\": 39, \"ঊ\": 40, \"৬\": 41, \"ঈ\": 42, \"ঋ\": 43, \"ঠ\": 44, \"ত\": 45, \"এ\": 46, \"৫\": 47, \"আ\": 48, \"ছ\": 49, \"ূ\": 50, \"ব\": 51, \"ঐ\": 52, \"প\": 53, \"ী\": 54, \"ড\": 55, \"৭\": 56, \"ণ\": 57, \"ফ\": 58, \"ু\": 59, \"ৃ\": 60, \"১\": 61, \"|\": 62, \"৮\": 63, \"‍\": 64, \"i\": 65, \"ৰ\": 66, \"ঔ\": 67, \"ভ\": 68, \"‎\": 69, \"ঙ\": 70, \"ৎ\": 71, \"ঘ\": 72, \"দ\": 73, \"২\": 74, \"ঝ\": 75, \"l\": 76, \"য়\": 77, \"জ\": 78, \"ক\": 79, \"ন\": 80, \"য\": 81, \"ে\": 82, \"র\": 83, \"৩\": 84, \"ঢ\": 85, \"ঁ\": 86}","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.133825Z","iopub.execute_input":"2022-08-21T17:15:59.134339Z","iopub.status.idle":"2022-08-21T17:15:59.150782Z","shell.execute_reply.started":"2022-08-21T17:15:59.13431Z","shell.execute_reply":"2022-08-21T17:15:59.149195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.195294Z","iopub.execute_input":"2022-08-21T17:15:59.19611Z","iopub.status.idle":"2022-08-21T17:15:59.205028Z","shell.execute_reply.started":"2022-08-21T17:15:59.196067Z","shell.execute_reply":"2022-08-21T17:15:59.203265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2CTCTokenizer\n\ntokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"./\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.207717Z","iopub.execute_input":"2022-08-21T17:15:59.208079Z","iopub.status.idle":"2022-08-21T17:15:59.758993Z","shell.execute_reply.started":"2022-08-21T17:15:59.208051Z","shell.execute_reply":"2022-08-21T17:15:59.757709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2FeatureExtractor\n\nfeature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.767364Z","iopub.execute_input":"2022-08-21T17:15:59.770787Z","iopub.status.idle":"2022-08-21T17:15:59.788918Z","shell.execute_reply.started":"2022-08-21T17:15:59.770724Z","shell.execute_reply":"2022-08-21T17:15:59.787606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor\n\nprocessor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.791696Z","iopub.execute_input":"2022-08-21T17:15:59.792129Z","iopub.status.idle":"2022-08-21T17:15:59.80632Z","shell.execute_reply.started":"2022-08-21T17:15:59.792089Z","shell.execute_reply":"2022-08-21T17:15:59.804565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass dldata(Dataset):\n    \n    def __init__(self,df):\n        self.df = df\n        self.all_paths=df['wav_path']\n        self.sen=df['sentence']\n        \n    def __getitem__(self,i):\n        if i>= len(self.df):\n            raise IndexError('Index out of range')\n        \n        \n        aud_path=self.all_paths[i]\n        aud_arr,_=wav_read(aud_path)\n        label=self.sen[i]\n        \n        with processor.as_target_processor():\n            label_en = processor(label).input_ids\n        \n        return {'input_values':aud_arr,\n                'input_ids':label_en,\n               'input_length':len(aud_arr)}\n    \n    def __len__(self):\n        return len(self.df)\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:15:59.808748Z","iopub.execute_input":"2022-08-21T17:15:59.809821Z","iopub.status.idle":"2022-08-21T17:15:59.829527Z","shell.execute_reply.started":"2022-08-21T17:15:59.809778Z","shell.execute_reply":"2022-08-21T17:15:59.827915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to ran out of gpu time and other issues, I only trained it with first 1000 train samples.","metadata":{}},{"cell_type":"code","source":"train_dataset=dldata(train_df[0:1000])\nvalid_dataset=dldata(valid_df[0:200])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"id":"tborvC9hx88e","execution":{"iopub.status.busy":"2022-08-21T17:15:59.833106Z","iopub.execute_input":"2022-08-21T17:15:59.83465Z","iopub.status.idle":"2022-08-21T17:15:59.859692Z","shell.execute_reply.started":"2022-08-21T17:15:59.834607Z","shell.execute_reply":"2022-08-21T17:15:59.858216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"id":"lbQf5GuZyQ4_","execution":{"iopub.status.busy":"2022-08-21T17:15:59.861847Z","iopub.execute_input":"2022-08-21T17:15:59.86263Z","iopub.status.idle":"2022-08-21T17:15:59.875225Z","shell.execute_reply.started":"2022-08-21T17:15:59.862588Z","shell.execute_reply":"2022-08-21T17:15:59.873821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")","metadata":{"id":"9Xsux2gmyXso","outputId":"18ceeb9e-1a0d-4ee8-f511-a12ad3608bf1","execution":{"iopub.status.busy":"2022-08-21T17:15:59.879196Z","iopub.execute_input":"2022-08-21T17:15:59.880811Z","iopub.status.idle":"2022-08-21T17:16:01.074459Z","shell.execute_reply.started":"2022-08-21T17:15:59.880769Z","shell.execute_reply":"2022-08-21T17:16:01.073016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"id":"1XZ-kjweyTy_","execution":{"iopub.status.busy":"2022-08-21T17:16:01.077642Z","iopub.execute_input":"2022-08-21T17:16:01.078516Z","iopub.status.idle":"2022-08-21T17:16:01.087254Z","shell.execute_reply.started":"2022-08-21T17:16:01.078468Z","shell.execute_reply":"2022-08-21T17:16:01.085691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'ai4bharat/indicwav2vec_v1_bengali' is the best pretrained model that I have found. IndicWav2Vec is a multilingual speech model pretrained on 40 Indian langauges. This model represents the largest diversity of Indian languages in the pool of multilingual speech models. We fine-tune this model for downstream ASR for 9 languages and obtain state-of-the-art results on 3 public benchmarks, namely MUCS, MSR and OpenSLR.\n\nLINK: https://indicnlp.ai4bharat.org/indicwav2vec/","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2ForCTC\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\"ai4bharat/indicwav2vec_v1_bengali\",\n    attention_dropout=0.0,\n    hidden_dropout=0.0,\n    feat_proj_dropout=0.0,\n    mask_time_prob=0.05,\n    layerdrop=0.0,\n    ctc_loss_reduction=\"mean\", \n    pad_token_id=processor.tokenizer.pad_token_id,\n    vocab_size=len(processor.tokenizer)\n)","metadata":{"id":"e7cqAWIayn6w","outputId":"3e6cebea-78ef-45df-87b0-f63b78ba9644","execution":{"iopub.status.busy":"2022-08-21T17:16:01.088858Z","iopub.execute_input":"2022-08-21T17:16:01.090582Z","iopub.status.idle":"2022-08-21T17:17:57.929529Z","shell.execute_reply.started":"2022-08-21T17:16:01.090534Z","shell.execute_reply":"2022-08-21T17:17:57.928011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"id":"oGI8zObtZ3V0","execution":{"iopub.status.busy":"2022-08-21T17:17:57.931635Z","iopub.execute_input":"2022-08-21T17:17:57.932382Z","iopub.status.idle":"2022-08-21T17:17:57.945283Z","shell.execute_reply.started":"2022-08-21T17:17:57.932338Z","shell.execute_reply":"2022-08-21T17:17:57.942786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have started this competetion only 1 week ago. That's why I couldn't find enough time to train this model. Also I wwas run out of gpu time. I have only traine dthis model with 1000 train data for 30 epochs. I believe, If I train this model with more train data, then the performance will be much higher.","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nstep_n = 100 \n\ntraining_args = TrainingArguments(\n  output_dir=\"./\",\n  group_by_length=True,\n  per_device_train_batch_size=16,\n  gradient_accumulation_steps=2,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=30,\n  gradient_checkpointing=True,\n  fp16=True,\n  save_steps=step_n,\n  eval_steps=step_n,\n  logging_steps=step_n,\n  learning_rate=3e-4,\n  warmup_steps=500,\n  save_total_limit=2,\n  push_to_hub=False,\n)","metadata":{"id":"KbeKSV7uzGPP","execution":{"iopub.status.busy":"2022-08-21T17:17:57.948114Z","iopub.execute_input":"2022-08-21T17:17:57.949226Z","iopub.status.idle":"2022-08-21T17:17:58.302208Z","shell.execute_reply.started":"2022-08-21T17:17:57.949167Z","shell.execute_reply":"2022-08-21T17:17:58.300711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, all instances can be passed to Trainer and we are ready to start training!","metadata":{"id":"OsW-WZcL1ZtN"}},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"id":"rY7vBmFCPFgC","outputId":"c47ecc78-5259-44db-c121-5bd7945defb8","execution":{"iopub.status.busy":"2022-08-21T17:17:58.304415Z","iopub.execute_input":"2022-08-21T17:17:58.305451Z","iopub.status.idle":"2022-08-21T17:18:07.522232Z","shell.execute_reply.started":"2022-08-21T17:17:58.305403Z","shell.execute_reply":"2022-08-21T17:18:07.520756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{"id":"rpvZHM1xReIW"}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:18:07.524712Z","iopub.execute_input":"2022-08-21T17:18:07.527408Z","iopub.status.idle":"2022-08-21T17:18:07.536504Z","shell.execute_reply.started":"2022-08-21T17:18:07.527344Z","shell.execute_reply":"2022-08-21T17:18:07.534965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"9fRr9TG5pGBl","outputId":"122ea040-7b24-452a-c7d4-7e72e1c46973","execution":{"iopub.status.busy":"2022-08-21T17:18:07.539146Z","iopub.execute_input":"2022-08-21T17:18:07.540526Z","iopub.status.idle":"2022-08-21T18:42:37.540556Z","shell.execute_reply.started":"2022-08-21T17:18:07.54048Z","shell.execute_reply":"2022-08-21T18:42:37.53911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:42:37.543035Z","iopub.execute_input":"2022-08-21T18:42:37.544598Z","iopub.status.idle":"2022-08-21T18:42:39.037065Z","shell.execute_reply.started":"2022-08-21T18:42:37.544527Z","shell.execute_reply":"2022-08-21T18:42:39.035448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r my_model.zip ./checkpoint-900","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:47:21.193037Z","iopub.execute_input":"2022-08-21T18:47:21.194447Z","iopub.status.idle":"2022-08-21T18:51:31.16607Z","shell.execute_reply.started":"2022-08-21T18:47:21.194395Z","shell.execute_reply":"2022-08-21T18:51:31.164259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink \nFileLink(r'./my_model.zip')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:57:53.697945Z","iopub.execute_input":"2022-08-21T18:57:53.698762Z","iopub.status.idle":"2022-08-21T18:57:53.710727Z","shell.execute_reply.started":"2022-08-21T18:57:53.698728Z","shell.execute_reply":"2022-08-21T18:57:53.709362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resources:\n* blog: https://huggingface.co/blog/fine-tune-xlsr-wav2vec2\n* pretrained model: https://huggingface.co/ai4bharat/indicwav2vec_v1_bengali\n","metadata":{}}]}